{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhLJIsuHh9xofVHBdA5KIH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradhyumnaPrakash/Ancient-Indian-Philosophy-Based-RAG-Systems/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "WFZy_ZKBeXRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Bhagavad Gita into JSONL**\n",
        "\n"
      ],
      "metadata": {
        "id": "6h-2N9bCfeaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Bhagavad Gita and Itihasa Dataset\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "OxBpNGDheY0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Bhagavad Gita dataset\n",
        "gita = pd.read_csv(\"Bhagwad_Gita.csv\")  # change filename as needed\n",
        "\n",
        "print(gita.head())\n",
        "print(gita.columns)\n",
        "print(\"Rows in Bhagavad Gita:\", len(gita))\n"
      ],
      "metadata": {
        "id": "Qq42BN0adRGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the important ones\n",
        "gita = gita[['Transliteration', 'EngMeaning']]\n",
        "\n",
        "gita = gita.rename(columns={\n",
        "    'Transliteration': 'sanskrit_text',\n",
        "    'EngMeaning': 'english_text'\n",
        "})\n",
        "\n",
        "# Preview\n",
        "gita.head()"
      ],
      "metadata": {
        "id": "UifbeVLGdTvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as CSV\n",
        "gita.to_csv(\"bhagavad_gita_clean.csv\", index=False)\n",
        "\n",
        "# Save as JSONL\n",
        "import json\n",
        "\n",
        "with open(\"bhagavad_gita_clean.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in gita.iterrows():\n",
        "        record = {\n",
        "            \"english_text\": row[\"english_text\"],\n",
        "            \"sanskrit_text\": row[\"sanskrit_text\"]\n",
        "        }\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"Rows in Bhagavad Gita:\", len(gita))"
      ],
      "metadata": {
        "id": "dH4QfWUkdswj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Itihasa into JSONL**"
      ],
      "metadata": {
        "id": "cBXgB_4jgxTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load them\n",
        "train = pd.read_csv(\"Itihasa_training.csv\")\n",
        "test  = pd.read_csv(\"Itihasa_testing.csv\")\n",
        "val   = pd.read_csv(\"Itihasa_validation.csv\")\n",
        "\n",
        "# Combine\n",
        "df = pd.concat([train, test, val], ignore_index=True)\n",
        "\n",
        "# Save as a single CSV\n",
        "df.to_csv(\"itihasa.csv\", index=False)\n",
        "\n",
        "print(\"Combined CSV saved as itihasa.csv\")"
      ],
      "metadata": {
        "id": "uXVZmf-peijd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only English + Sanskrit columns, rename them\n",
        "df_jsonl = df[[\"English\", \"Sanskrit\"]].rename(columns={\n",
        "    \"English\": \"english_text\",\n",
        "    \"Sanskrit\": \"sanskrit_text\"\n",
        "})\n",
        "\n",
        "# Save to JSONL\n",
        "with open(\"itihasa.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in df_jsonl.iterrows():\n",
        "        f.write(row.to_json(force_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"JSONL saved as itihasa.jsonl\")"
      ],
      "metadata": {
        "id": "YajHhgjQfc7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine Gita and Itihasa**"
      ],
      "metadata": {
        "id": "2WQHnhtmg8nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def read_jsonl(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "gita = read_jsonl(\"bhagavad_gita_clean.jsonl\")\n",
        "iti  = read_jsonl(\"itihasa.jsonl\")\n",
        "\n",
        "combined = []\n",
        "for row in gita:\n",
        "    row[\"source\"] = \"bhagavad_gita\"\n",
        "    combined.append(row)\n",
        "for row in iti:\n",
        "    row[\"source\"] = \"itihasa\"\n",
        "    combined.append(row)\n",
        "\n",
        "with open(\"itihasa_gita_combined.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for r in combined:\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"Saved itihasa_gita_combined.jsonl\")"
      ],
      "metadata": {
        "id": "zBeyRD87g_ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAISS Index"
      ],
      "metadata": {
        "id": "2LzwvR61i4lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "5FS9qkQEi79i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pandas as pd\n",
        "\n",
        "# Use English text for embeddings\n",
        "texts = [d[\"english_text\"] for d in docs]\n",
        "\n",
        "# Multilingual embedding model (good for English + Sanskrit in context)\n",
        "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "embs = model.encode(texts, normalize_embeddings=True, convert_to_numpy=True)\n",
        "\n",
        "# Build FAISS index\n",
        "dim = embs.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(embs.astype(\"float32\"))\n",
        "\n",
        "# Metadata store (for later retrieval of Sanskrit + source)\n",
        "store = pd.DataFrame({\n",
        "    \"id\": range(len(docs)),\n",
        "    \"english_text\": [d[\"english_text\"] for d in docs],\n",
        "    \"sanskrit_text\": [d.get(\"sanskrit_text\", \"\") for d in docs],\n",
        "    \"source\": [d[\"source\"] for d in docs]\n",
        "})\n"
      ],
      "metadata": {
        "id": "FtftMr3njaSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "n-GFhG-BkN0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieval-only**"
      ],
      "metadata": {
        "id": "Yco5HjrZkQoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def faiss_search(query, k=3):\n",
        "    qv = model.encode([query], normalize_embeddings=True, convert_to_numpy=True)\n",
        "    D, I = index.search(qv.astype(\"float32\"), k)\n",
        "    results = store.iloc[I[0]].copy()\n",
        "    results[\"score\"] = D[0]\n",
        "    return results\n",
        "\n",
        "def retrieval_only(query, k=3):\n",
        "    hits = faiss_search(query, k=k)\n",
        "    # Return English + Sanskrit verses\n",
        "    return \"\\n\\n---\\n\\n\".join(\n",
        "        f\"English: {row['english_text']}\\nSanskrit: {row['sanskrit_text']}\"\n",
        "        for _, row in hits.iterrows()\n",
        "    )"
      ],
      "metadata": {
        "id": "V1XG2PVtjdDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    # Philosophy & Metaphysics\n",
        "    \"What happens to the soul after death?\",\n",
        "    \"Why should I follow my dharma?\",\n",
        "    \"How can I practice detachment in daily life?\",\n",
        "    \"What does karma really mean for my future?\",\n",
        "    \"How can knowledge help me reach peace?\",\n",
        "\n",
        "    # Emotion & Self-Mastery\n",
        "    \"How do I control my anger?\",\n",
        "    \"What should I do when I feel afraid?\",\n",
        "    \"How do I deal with grief after losing someone?\",\n",
        "    \"Why do I feel so much hesitation before making a big decision?\",\n",
        "    \"How can I overcome desire and temptation?\",\n",
        "\n",
        "    # Interpersonal & Leadership\n",
        "    \"How should a good leader behave?\",\n",
        "    \"What is the right way to treat my teacher or mentor?\",\n",
        "    \"How can I show respect to someone I look up to?\",\n",
        "    \"How should I stay loyal to my friends?\",\n",
        "    \"How can I balance my family responsibilities with my work?\",\n",
        "\n",
        "    # Therapy & Self-Growth\n",
        "    \"How do I handle stress when life feels overwhelming?\",\n",
        "    \"Can meditation help me control my emotions?\",\n",
        "    \"How do I let go of attachments that hurt me?\",\n",
        "    \"What should I do when I feel stuck in a personal crisis?\",\n",
        "    \"How can I become more resilient after failure?\"\n",
        "]\n",
        "\n",
        "\n",
        "results = []\n",
        "for q in questions:\n",
        "    ans = retrieval_only(q, k=3)\n",
        "    results.append({\"question\": q, \"retrieval_answer\": ans})\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(\"retrieval_results.csv\", index=False)\n",
        "\n",
        "print(\"All retrieval-only answers saved to retrieval_results.csv\")\n",
        "df_results.head()\n"
      ],
      "metadata": {
        "id": "LiNW4NT_j5nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('retrieval_results_final.csv')"
      ],
      "metadata": {
        "id": "kRSw41TlkZ6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base Qwen and RAG+Qwen"
      ],
      "metadata": {
        "id": "JJC8ssXenYew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu sentence-transformers transformers accelerate torch bitsandbytes\n"
      ],
      "metadata": {
        "id": "ogEv1rGcncoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "qwen_tok = AutoTokenizer.from_pretrained(model_name)\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16   # run in fp16 on GPU\n",
        ")"
      ],
      "metadata": {
        "id": "hkeqpwvhngCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plain_qwen(query):\n",
        "    prompt = (\n",
        "        \"Answer the question using only the passages below. \"\n",
        "        \"Explain their meaning in clear, simple English, at least 3 sentences long. \"\n",
        "        \"Use ancient Sanskrit scriptures Bhagavad Gita and Itihasa to answer\"\n",
        "        \"skip the question if it takes too long\"\n",
        "        f\"Question: {query}\\nAnswer:\"\n",
        "    )\n",
        "    inputs = qwen_tok(prompt, return_tensors=\"pt\", truncation=True).to(qwen_model.device)\n",
        "    outputs = qwen_model.generate(\n",
        "        **inputs,\n",
        "        do_sample=True, temperature=0.7, top_p=0.9,\n",
        "        min_new_tokens=60, max_new_tokens=250\n",
        "    )\n",
        "    return qwen_tok.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "xnt-wyaqnvYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plain_results = []\n",
        "for q in questions:\n",
        "    print(\"Plain Qwen:\", q)\n",
        "    plain_ans = plain_qwen(q)\n",
        "    plain_results.append({\"question\": q, \"plain_qwen_answer\": plain_ans})\n",
        "\n",
        "df_plain = pd.DataFrame(plain_results)\n",
        "df_plain.to_csv(\"plain_qwen_results.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"plain_qwen_results.csv\")"
      ],
      "metadata": {
        "id": "H_20E84Gn0Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_qwen(query, k=5):\n",
        "    # Step 1: Retrieve passages\n",
        "    hits = faiss_search(query, k=k)\n",
        "\n",
        "    # Step 2: Build prompt with context\n",
        "    prompt = build_prompt(query, hits)\n",
        "\n",
        "    # Step 3: Tokenize and run through Qwen\n",
        "    inputs = qwen_tok(prompt, return_tensors=\"pt\", truncation=True).to(qwen_model.device)\n",
        "    outputs = qwen_model.generate(\n",
        "        **inputs,\n",
        "        do_sample=True, temperature=0.7, top_p=0.9,\n",
        "        min_new_tokens=60, max_new_tokens=250\n",
        "    )\n",
        "\n",
        "    # Step 4: Decode output\n",
        "    return qwen_tok.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "hqKylsu1nhjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_results = []\n",
        "for q in questions:\n",
        "    print(\"RAG Qwen:\", q)\n",
        "    rag_ans = rag_qwen(q, k=3) #K=3\n",
        "    rag_results.append({\"question\": q, \"rag_qwen_answer\": rag_ans})\n",
        "\n",
        "df_rag = pd.DataFrame(rag_results)\n",
        "df_rag.to_csv(\"rag_qwen_results_k_5_final.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"rag_qwen_results_k_5_final.csv\")"
      ],
      "metadata": {
        "id": "WSGGGU6in5pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_results = []\n",
        "for q in questions:\n",
        "    print(\"RAG Qwen:\", q)\n",
        "    rag_ans = rag_qwen(q, k=5) #K=5\n",
        "    rag_results.append({\"question\": q, \"rag_qwen_answer\": rag_ans})\n",
        "\n",
        "df_rag = pd.DataFrame(rag_results)\n",
        "df_rag.to_csv(\"rag_qwen_results_k_5_final.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"rag_qwen_results_k_5_final.csv\")"
      ],
      "metadata": {
        "id": "ZME0A1r6nkx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG+Gemini"
      ],
      "metadata": {
        "id": "ykeQieWzn2q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"INSERT YOUR API KEY HERE\")\n",
        "\n",
        "gemini = genai.GenerativeModel(\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "p79d-Tcyn-CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_gemini(query, k=5):\n",
        "    hits = faiss_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(\n",
        "        f\"English: {row['english_text']}\\nSanskrit: {row['sanskrit_text']}\"\n",
        "        for _, row in hits.iterrows()\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        \"Answer the question using only the passages below. \"\n",
        "        \"Explain their meaning in clear, simple English, at least 3 sentences long. \"\n",
        "        \"After your explanation, always include the exact Sanskrit verse(s) from the passages \"\n",
        "        \"that support your answer. Do not omit them. \"\n",
        "        \"Make sure to not just copy the passages, analyze and understand them and then reply in your own words.\"\n",
        "        \"skip the question if it takes too long\"\n",
        "        f\"{context}\\n\\n\"\n",
        "        f\"Question: {query}\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    response = gemini.generate_content(prompt)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "sJ9BgdeUoC-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Answers in Colab itself\n",
        "for q in questions:\n",
        "    print(\"=\"*80)\n",
        "    print(\"Q:\", q)\n",
        "    print(\"A:\", rag_gemini(q, k=3))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Uvc3grXhoJsZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}